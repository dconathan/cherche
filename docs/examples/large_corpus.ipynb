{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handle large corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We designed Cherche primarily to create a neural search pipeline on a corpus of moderate size. A large corpus is where not all documents can be stored in memory or when the retrievers `retrieve.TfIdf`, `retrieve.BM25Okapi`, `retrieve.Lunr` are not fast enough. If we want to work with large corpora, consider looking at [Jina](https://github.com/jina-ai/jina). Nevertheless, Cherche is compatible with a neural search pipeline on large corpora using Python's Elasticsearch client `retrieve.Elastic`. **In this tutorial, we will use ElasticSearch to act as a retriever and to store the ranker embeddings.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, to establish the connection with Elasticsearch, we need to have a server with Elasticsearch running or to run Elasticsearch on our local machine. The installation of Elasticsearch is explained [here](https://www.elastic.co/downloads/elasticsearch). The first step is to initialise the `retrieve.Elastic` retriever. `retrieve.Elastic` takes a parameter `es` that establishes the connection with Elasticsearch. \n",
    "\n",
    "Also, to create a neural search on a large corpus, we will need a GPU at least to pre-compute document embeddings. However, a GPU is not mandatory in a production environment if we do not want to answer questions or summarize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this tutorial, we will present two distinct solutions for implementing the neural search pipeline.**\n",
    "\n",
    "- **Scenario 1: Connecting remotely to ElasticSearch from the GPU computer to index documents and embeddings.**\n",
    "- **Scenario 2: Index documents and embeddings on Elasticsearch without a remote connection.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 1: Connect remotely to ElasticSearch from the GPU computer to index documents and embeddings.\n",
    "\n",
    "We are on the computer that owns a GPU here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cherche import retrieve, rank\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from elasticsearch import Elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My Elasticsearch server runs locally on port 9200 on my computer. You should replace `localhost:9200` with your own Elasticsearch adress if it's remote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elasticsearch is running.\n"
     ]
    }
   ],
   "source": [
    "es = Elasticsearch(hosts=\"localhost:9200\")\n",
    "\n",
    "if es.ping():\n",
    "    print(\"Elasticsearch is running.\")\n",
    "else:\n",
    "    print(\"Elasticsearch is not running.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We declare our neural search pipeline make of a ranker and a retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = retrieve.Elastic(\n",
    "    es = es,\n",
    "    key = \"id\",\n",
    "    on = \"document\",\n",
    "    k = 100,\n",
    "    index = \"large_corpus\"\n",
    ")\n",
    "\n",
    "ranker = rank.Encoder(\n",
    "    key = \"id\",\n",
    "    on = \"document\",\n",
    "    encoder = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\", device=\"cuda\").encode,\n",
    "    k = 10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will be able to index our documents and embeddings simultaneously. This process takes time if we have a lot of documents. We could run it in parallel from several computers for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Elastic retriever\n",
       " \t key: id\n",
       " \t on: document\n",
       " \t documents: 3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imagine 1 millions documents instead of 3. ðŸ˜…\n",
    "\n",
    "documents = [\n",
    "    {\"id\": 0, \"document\": \"Toulouse is a municipality in south-west France. With 486,828 inhabitants as of 1 January 2018, Toulouse is the fourth most populous commune in France after Paris, Marseille and Lyon, having gained 101,000 inhabitants over the last 47 years (1968-2015)\"},\n",
    "    {\"id\": 1, \"document\": \"Montreal is the main city of Quebec. A large island metropolis and port on the St. Laurent River at the foot of the Lachine Rapids, it is the second most populous city in Canada, after Toronto.\"},\n",
    "    {\"id\": 2, \"document\": \"Bordeaux is a French commune located in the Gironde department in the Nouvelle-Aquitaine region.\"}\n",
    "]\n",
    "\n",
    "retriever.add_embeddings(documents=documents, ranker=ranker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et voilÃ ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 2: Index documents and embeddings on Elasticsearch without a remote connection.\n",
    "\n",
    "We are on the GPU computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from cherche import rank\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker = rank.Encoder(\n",
    "    key = \"id\",\n",
    "    on = \"document\",\n",
    "    encoder = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\", device=\"cuda\").encode,\n",
    "    k = 10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the GPU machine, we can compute document embeddings and save the embeddings as a json file or Pickle file for loading on the computer that has access to ElasticSearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imagine 1 millions documents instead of 3. ðŸ˜…\n",
    "\n",
    "documents = [\n",
    "    {\"id\": 0, \"document\": \"Toulouse is a municipality in south-west France. With 486,828 inhabitants as of 1 January 2018, Toulouse is the fourth most populous commune in France after Paris, Marseille and Lyon, having gained 101,000 inhabitants over the last 47 years (1968-2015)\"},\n",
    "    {\"id\": 1, \"document\": \"Montreal is the main city of Quebec. A large island metropolis and port on the St. Laurent River at the foot of the Lachine Rapids, it is the second most populous city in Canada, after Toronto.\"},\n",
    "    {\"id\": 2, \"document\": \"Bordeaux is a French commune located in the Gironde department in the Nouvelle-Aquitaine region.\"}\n",
    "]\n",
    "\n",
    "for document, embedding in zip(documents, ranker.embs(documents=documents)):\n",
    "\n",
    "    # embeddings is important here, you should not change the key.\n",
    "    document[\"embedding\"] = embedding.tolist()\n",
    "\n",
    "# You can process the documents per batch and export them in differents json files.\n",
    "with open(\"documents_embeddings.json\", \"w\") as documents_embeddings:\n",
    "    json.dump(documents, documents_embeddings, indent = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now on a computer that has access to the running Elasticsearch server.  We have previously transferred the json file from the machine that has a GPU to the machine that has access to Elasticsearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from cherche import retrieve\n",
    "from elasticsearch import Elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My Elasticsearch server runs locally on port 9200 on my computer. You should replace `localhost:9200` with your own Elasticsearch adress if it's remote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elasticsearch is running.\n"
     ]
    }
   ],
   "source": [
    "es = Elasticsearch(hosts=\"localhost:9200\")\n",
    "\n",
    "if es.ping():\n",
    "    print(\"Elasticsearch is running.\")\n",
    "else:\n",
    "    print(\"Elasticsearch is not running.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be able to index the documents and embeddings that we have previously calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Elastic retriever\n",
       " \t key: id\n",
       " \t on: document\n",
       " \t documents: 3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"documents_embeddings.json\", \"r\") as documents_embeddings:\n",
    "    json.load(documents_embeddings)\n",
    "\n",
    "retriever = retrieve.Elastic(\n",
    "    key = \"id\",\n",
    "    on = \"document\",\n",
    "    es = es,\n",
    "    k = 100,\n",
    "    index = \"large_corpus\"\n",
    ")\n",
    "\n",
    "retriever.add(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et voila."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now query your neural search pipeline via the `retrieve.Elastic` retriever without a GPU and have decent performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cherche import retrieve, rank\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "es = Elasticsearch(hosts=\"localhost:9200\")\n",
    "\n",
    "retriever = retrieve.Elastic(\n",
    "    key = \"id\",\n",
    "    on = \"document\",\n",
    "    es = es,\n",
    "    k = 100,\n",
    "    index = \"large_corpus\"\n",
    ")\n",
    "\n",
    "ranker = rank.Encoder(\n",
    "    key = \"id\",\n",
    "    on = \"document\",\n",
    "    encoder = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\").encode,\n",
    "    k = 1,\n",
    ")\n",
    "\n",
    "search = retriever + ranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 0,\n",
       "  'document': 'Toulouse is a municipality in south-west France. With 486,828 inhabitants as of 1 January 2018, Toulouse is the fourth most populous commune in France after Paris, Marseille and Lyon, having gained 101,000 inhabitants over the last 47 years (1968-2015)',\n",
       "  'similarity': 0.6678053305504484}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search(\"Toulouse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time for a real demo on 600,000 documents - CPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the demonstration more convincing, I indexed 600,000 wikipedia articles following scenario 2 with google collaboratory to calculate the embeddings and an Elasticsearch server running locally on my pc. Now we don't need a GPU anymore since we pre-computed embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cherche import retrieve, rank\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "es = Elasticsearch(hosts=\"localhost:9200\")\n",
    "\n",
    "retriever = retrieve.Elastic(\n",
    "    key=\"id\",\n",
    "    es = es,\n",
    "    on = \"document\",\n",
    "    k = 100,\n",
    "    index = \"wiki\" # My wiki index contains 700000 documents\n",
    ")\n",
    "\n",
    "ranker = rank.Encoder(\n",
    "    key=\"id\",\n",
    "    encoder = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\").encode,\n",
    "    on = \"document\",\n",
    "    k = 10,\n",
    ")\n",
    "\n",
    "search = retriever + ranker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neural search pipeline references 600,000 documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Elastic retriever\n",
       " \t key: id\n",
       " \t on: document\n",
       " \t documents: 700000\n",
       "Encoder ranker\n",
       "\t key: id\n",
       "\t on: document\n",
       "\t k: 10\n",
       "\t similarity: cosine"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On my computer, which only uses a CPU, it takes 100 ms to query all these documents, which is great. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.5 ms Â± 7.66 ms per loop (mean Â± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit search(\"Toulouse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'document': 'Toulouse MÃ©tropole is the metropolis, an intercommunal structure, centred on the city of Toulouse. It is located in the Haute-Garonne department, in the Occitanie region, southern France.',\n",
       "  'similarity': 0.6366361226971764},\n",
       " {'document': 'France is home to aerospace giant Airbus, which has its headquarters and main facilities located in Toulouse.',\n",
       "  'similarity': 0.5271759181852023},\n",
       " {'document': 'It was created on January 1, 2015, succeeding the urban community of Toulouse, which had itself succeeded in 2009 and 2001 to previous districts created in 1992 with less powers than either the urban community or the current metropolitan region.',\n",
       "  'similarity': 0.49571503621282487},\n",
       " {'document': 'Due to local political feuds, Toulouse MÃ©tropole only hosts 59% of the population of the metropolitan area (see infobox at Toulouse article for the metropolitan area), the other independent communes of the metropolitan area having refused to join in, notably Muret and the technopolis of LabÃ¨ge-Innopole.',\n",
       "  'similarity': 0.4901021019345147},\n",
       " {'document': 'The southwest of France, around Toulouse, had a particular style, more vivid and active than the north. A remarkable group of Romanesque sculpture is found in the decoration of the Basilica of Saint-Sernin, Toulouse in Toulouse, dating to the late 11th and early 12th century. The figures are much more realistic, and make skillful use of shadows and light to bring out the details.',\n",
       "  'similarity': 0.4778608323423781},\n",
       " {'document': 'LExpress du Midi was a daily newspaper published in Toulouse and serving that city as well as the surrounding Haute-Garonne region in southern France. It was published between 1891 and 1938.',\n",
       "  'similarity': 0.4501763082283748},\n",
       " {'document': 'Born in Toulouse on 31 August 1845, Camille Ournac, became a wholesale wine merchant, a miller and then Conseil gÃ©nÃ©ral of French Departments, Ournac was the first of a succession of radical socialist mayors of Toulouse\\xa0who founded the labor exchange and set up the first horse-drawn streetcars in the city. His tenure was from 20 May 1888 until October 1892.',\n",
       "  'similarity': 0.4361270053417485},\n",
       " {'document': 'Marie-AimÃ©e Miclos was born in Toulouse. She studied at the Conservatoire de Toulouse and the Conservatoire de Paris, with and with Henri Herz.',\n",
       "  'similarity': 0.43415172022157345},\n",
       " {'document': 'PSOE, UGT, PCE, CNT, Juventudes Socialistas de EspaÃ±a (JSE),\\xa0 Movimiento Libertario EspaÃ±ol (MLE) and the Moviment Socialista de Catalunya (MSC) continued their struggle in exile.\\xa0 From 1944 to 1960, the French city of Toulouse served as a major publishing hub for many of these organizations home in exile.\\xa0 The city of Toulouse itself would see around 40,000 exiles from these groups settle permanently in the city.',\n",
       "  'similarity': 0.43114780538880315},\n",
       " {'document': 'PSOE, UGT, PCE, CNT, Juventudes Socialistas de EspaÃ±a (JSE),\\xa0 Movimiento Libertario EspaÃ±ol (MLE) and the Moviment Socialista de Catalunya (MSC) continued their struggle in exile.\\xa0 From 1944 to 1960, the French city of Toulouse served as a major publishing hub for many of these organizations home in exile.\\xa0 The city of Toulouse itself would see around 40,000 exiles from these groups settle permanently in the city.',\n",
       "  'similarity': 0.43114780538880315}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search(\"Toulouse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course we can connect a question answering model or a summarization model to our neural pipeline. **However, these models are heavier and require a GPU to maintain the performance level.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cherche import qa\n",
    "from transformers import pipeline\n",
    "\n",
    "search = retriever + ranker + qa.QA(\n",
    "    model = pipeline(\"question-answering\", model = \"deepset/roberta-base-squad2\", tokenizer = \"deepset/roberta-base-squad2\"),\n",
    "    on = \"document\",\n",
    "    k = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'start': 10,\n",
       "  'end': 49,\n",
       "  'answer': 'dynamically-typed and garbage-collected',\n",
       "  'qa_score': 0.8619149327278137,\n",
       "  'document': 'Python is dynamically-typed and garbage-collected. It supports multiple programming paradigms, including structured (particularly, procedural), object-oriented and functional programming.',\n",
       "  'similarity': 0.701137335987238},\n",
       " {'start': 10,\n",
       "  'end': 77,\n",
       "  'answer': 'an interpreted, high-level and general-purpose programming language',\n",
       "  'qa_score': 0.6966809630393982,\n",
       "  'document': 'Python is an interpreted, high-level and general-purpose programming language. Pythons design philosophy emphasizes code readability with its notable use of significant whitespace.',\n",
       "  'similarity': 0.8061618668192251}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search(\"What is Python?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarization pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cherche import summary\n",
    "\n",
    "search = retriever + ranker + summary.Summary(\n",
    "    model = pipeline(\"summarization\", model=\"sshleifer/distilbart-cnn-6-6\", tokenizer=\"sshleifer/distilbart-cnn-6-6\", framework=\"pt\"),\n",
    "    on = \"document\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Python is an interpreted, high-level and general-purpose programming language. It supports multiple programming paradigms, including structured (particularly'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search(\"What is Python?\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7b170744ab9cf7446ed3e27cb2734f2273f9ffda6b52a7d603d13471f7231bb1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
